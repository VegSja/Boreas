# dbt Boreas - Data Transformation

This dbt project transforms raw avalanche and weather data into clean, analytics-ready datasets using a medallion architecture (Bronze â†’ Silver â†’ Gold).

## Architecture

### Data Layers
- **ğŸ¥‰ Bronze (1_bronze)**: Raw data from DLT pipelines
- **ğŸ¥ˆ Silver (2_silver)**: Cleaned and standardized data
- **ğŸ¥‡ Gold (3_gold)**: Business logic and aggregated analytics

## Quick Start

### Prerequisites
- dbt-core >= 1.11.2
- dbt-duckdb >= 1.10.0
- DuckDB >= 1.4.3
- [uv](https://docs.astral.sh/uv/) package manager
- Completed DLT pipeline execution

### Setup

1. **Install dependencies**:
```bash
uv sync
```

2. **Configure dbt profile** (`profiles.yml`):
```yaml
dbt_boreas:
  target: dev
  outputs:
    dev:
      type: duckdb
      path: '../boreas.duckdb'
      schema: main
```

2. **Install dbt dependencies**:
```bash
cd dbt_boreas
uv run dbt deps
```

3. **Run transformations**:
```bash
# Run all models
uv run dbt run

# Run specific layer
uv run dbt run --select models/2_silver
uv run dbt run --select models/3_gold

# Run with full refresh
uv run dbt run --full-refresh
```

## Data Models

### Bronze Layer (`1_bronze`)
Raw data ingested by DLT pipelines:

**Sources**:
- `avalanche_danger_levels` - Raw avalanche warnings from API
- `weather_forecast` - Weather forecast data
- `weather_historic` - Historical weather data
- `regions` - Regional boundary and metadata

### Silver Layer (`2_silver`)
Cleaned and standardized data:

**Models**:
- `fact_avalanche_danger.sql` - Standardized avalanche danger records
- `fact_weather.sql` - Unified weather data (forecast + historic)
- `dim_regions.sql` - Regional dimension with geographic boundaries

**Key Transformations**:
- Data type standardization
- Null value handling
- Consistent field naming
- Deduplication

### Gold Layer (`3_gold`)
Business logic and analytics:

**Models**:
- `avalanche_average_weather_per_region.sql` - Regional weather aggregated with avalanche data

**Features**:
- Regional weather averages per day
- Avalanche danger correlation
- Geographic boundary integration
- Date-based aggregation

## Configuration

### Project Settings (`dbt_project.yml`)
```yaml
models:
  dbt_boreas:
    1_bronze:
      +materialized: table
      +schema: 1_bronze
    2_silver:
      +materialized: table
      +schema: 2_silver
    3_gold:
      +materialized: table
      +schema: 3_gold
```

### Materializations
- **Tables**: All models for performance
- **Schema separation**: Logical layer separation
- **Incremental loading**: Available for large datasets

## ğŸ“ File Structure

```
dbt_boreas/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ 1_bronze/
â”‚   â”‚   â””â”€â”€ sources.yml          # Source definitions
â”‚   â”œâ”€â”€ 2_silver/
â”‚   â”‚   â”œâ”€â”€ dim_regions.sql      # Regional dimension
â”‚   â”‚   â”œâ”€â”€ fact_avalanche_danger.sql
â”‚   â”‚   â”œâ”€â”€ fact_weather.sql
â”‚   â”‚   â””â”€â”€ schema.yml           # Model documentation
â”‚   â””â”€â”€ 3_gold/
â”‚       â”œâ”€â”€ avalanche_average_weather_per_region.sql
â”‚       â””â”€â”€ schema.yml
â”œâ”€â”€ macros/
â”‚   â””â”€â”€ generate_schema_name.sql  # Custom schema naming
â”œâ”€â”€ dbt_project.yml              # Project configuration
â”œâ”€â”€ profiles.yml                 # Database connection
â””â”€â”€ packages.yml                 # Dependencies
```

## Data Quality

### Source Validation
- Primary key constraints
- Not-null validations
- Referential integrity checks

### Model Testing
```bash
# Run all tests
uv run dbt test

# Test specific models
uv run dbt test --select models/2_silver
```

### Data Lineage
```bash
# Generate documentation
uv run dbt docs generate
uv run dbt docs serve
```

## Development Workflow

### 1. Model Development
```bash
# Develop in dev environment
uv run dbt run --select +my_model+

# Test during development
uv run dbt test --select my_model
```

### 2. Incremental Updates
```bash
# Run only changed models
uv run dbt run --select state:modified+

# Fresh build when needed
uv run dbt run --full-refresh
```

### 3. Production Deployment
```bash
# Target production
uv run dbt run --target prod

# Full pipeline
uv run dbt build --target prod
```

## Key Metrics & KPIs

Generated by gold layer models:
- Regional avalanche danger trends
- Weather pattern correlation
- Geographic coverage statistics
- Data quality metrics

## Integration

### Upstream Dependencies
- DLT pipelines must complete successfully
- Source data availability in DuckDB

### Downstream Consumers
- Streamlit dashboard (`dashboard/app.py`)
- Analytics tools and reports
- Data exports and APIs

## ğŸ“š Resources

- [dbt Documentation](https://docs.getdbt.com/)
- [dbt-duckdb Plugin](https://github.com/duckdb/dbt-duckdb)
- [Medallion Architecture](https://docs.databricks.com/lakehouse/medallion.html)